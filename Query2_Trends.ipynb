{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfc = sqlContext.read.load('file:////home/cloudera/Downloads/Q2_INPUT.csv', \n",
    "                          format='com.databricks.spark.csv', \n",
    "                          header='true', \n",
    "                          inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- HashTag: string (nullable = true)\n",
      " |-- Timestamp: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfc.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/spark/python/pyspark/sql/dataframe.py:142: UserWarning: Use registerTempTable instead of registerAsTable.\n",
      "  warnings.warn(\"Use registerTempTable instead of registerAsTable.\")\n"
     ]
    }
   ],
   "source": [
    "dfc.registerAsTable('train_table')\n",
    "df1 = sqlContext.sql('SELECT HashTag, (MAX(Timestamp) - MIN(Timestamp))/60 AS Life_Time FROM train_table GROUP BY HashTag')\n",
    "df1.registerAsTable('train_table7')\n",
    "df1 = sqlContext.sql('SELECT * FROM train_table7 WHERE Life_Time>0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3889"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/spark/python/pyspark/sql/dataframe.py:142: UserWarning: Use registerTempTable instead of registerAsTable.\n",
      "  warnings.warn(\"Use registerTempTable instead of registerAsTable.\")\n"
     ]
    }
   ],
   "source": [
    "dfc.registerAsTable('train_table')\n",
    "df2 = sqlContext.sql('SELECT HashTag, COUNT(*) AS Occurance FROM train_table GROUP BY HashTag ORDER BY Occurance DESC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/spark/python/pyspark/sql/dataframe.py:142: UserWarning: Use registerTempTable instead of registerAsTable.\n",
      "  warnings.warn(\"Use registerTempTable instead of registerAsTable.\")\n"
     ]
    }
   ],
   "source": [
    "df2.registerAsTable('train_table12')\n",
    "df1.registerAsTable('train_table123')\n",
    "df3 = sqlContext.sql('SELECT train_table12.HashTag, Life_Time, Occurance, Life_Time / Occurance AS RATE_OF_OCCURANCE FROM train_table12 JOIN train_table123 ON train_table12.HashTag = train_table123.HashTag WHERE Life_Time > 600 ORDER BY RATE_OF_OCCURANCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+---------+-----------------+\n",
      "|             HashTag|        Life_Time|Occurance|RATE_OF_OCCURANCE|\n",
      "+--------------------+-----------------+---------+-----------------+\n",
      "|    beingsinglemeans|600.0006178021431|       61|9.836075701674478|\n",
      "|           vgmas2017|600.0045898834865|       61|9.836140817762073|\n",
      "|  nationalpretzelday|600.0070591688157|       61|9.836181297849437|\n",
      "|      bostonmarathon|600.0118890841802|       61|9.836260476789839|\n",
      "|mujerespatriasobe...|609.9984772165616|       62|9.838685116396155|\n",
      "|            riphabbo|609.9998202999433|       62|9.838706779031343|\n",
      "|          soufeiomas|610.0006432175636|       62|9.838720051896187|\n",
      "|       brasilemgreve|610.0021240671475|       62|9.838743936566896|\n",
      "|        ufcnashville|610.0050924658775|       62|9.838791813965766|\n",
      "|enlavidanodebefaltar|610.0119982163111|       62|9.838903197037276|\n",
      "|         emillyjudas|619.9956872185071|       63|9.841201384420748|\n",
      "|             14abril|620.0043028513591|       63|9.841338140497763|\n",
      "| meuprimeirobullying|620.0056519667307|       63|9.841359555027472|\n",
      "|    worldheritageday|620.0056820829709|       63| 9.84136003306303|\n",
      "|    australianvalues|620.0092298150063|       63|9.841416346269941|\n",
      "|               bbmas|620.0130271991094|       63|9.841476622208086|\n",
      "|      jesusdenazaret|629.9948204835256|       64|9.843669070055087|\n",
      "|        lavidaespara|629.9989532987277|       64| 9.84373364529262|\n",
      "| misemanacomienzacon|630.0013357480367|       64|9.843770871063073|\n",
      "|            taxmarch|630.0108617504437|       64|9.843919714850683|\n",
      "+--------------------+-----------------+---------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
